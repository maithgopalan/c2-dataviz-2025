---
title: Homework
author: Daniel Anderson
date: '2022-02-05'
assigned: '2022-02-07'
due: '2022-02-21'
slug: homework-2
categories:
  - Assignment
tags:
  - Homework
toc: true
---


```{r setup, include = FALSE}
knitr::opts_chunk$set(message = FALSE,
                      warning = FALSE,
                      echo = FALSE,
                      dev.args = list(bg="transparent"))

```

## Background
For this homework we will again use data from [#tidytuesday](https://twitter.com/hashtag/rstats), as well as from [Kaggle](https://www.kaggle.com), this time looking at data on [transit costs](https://github.com/rfordatascience/tidytuesday/blob/master/data/2021/2021-01-05/readme.md) (from #tidytuesday) and [crime rates in Denver, CO](https://www.kaggle.com/paultimothymooney/denver-crime-data) (from Kaggle). We will be using the `crime.csv` file from Kaggle. 

Please visit each of the previous links for more information on each data source.

## git/GitHub
Use of *git*/GitHub is optional for this homework. However, I encourage you to use these tools to help you become more fluent with them, and in particular their use in collaborating. I am therefore offering a small amount of extra credit (**3 points**) for all group members who complete this homework collaboratively. To obtain the three points extra credit, you must:

* Have more than two group members
* Use branching
* Use issues
* Have evidence in your commit history that all members contributed to the homework roughly equally

This is optional, but will provide you a small amount of "buffer" if you happen to lose points elsewhere on the lab.

## Getting Started

You can download the tidytuesday data using one of the following approaches:

```{r echo = TRUE, eval = FALSE}
library(tidyverse)

transit_cost <- read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-01-05/transit_cost.csv')

# install.packages("tidytuesdayR")
transit_cost <- tidytuesdayR::tt_load(2021, week = 2)
```

The Kaggle data can be downloaded either directly [from Kaggle](https://www.kaggle.com/paultimothymooney/denver-crime-data) or [from canvas](https://canvas.uoregon.edu/files/10502740/download?download_frd=1) (it was too large to post on GitHub). Note that if you do download the data directly from Kaggle your plots may not match mine exactly, given that the data are updated daily.


## Assignment

### Question 1
Use the transit costs data to reproduce the following plot. To do so, you will
need to do a small amount of data cleaning, then calculate the means and 
standard errors (of the mean) for each country. Please filter to only counties with at least three observations. To use actual country names,
rather than abbreviations, join your dataset with the output from the following

```{r eval = FALSE, echo = TRUE}
install.packages("countrycode")
country_codes <- countrycode::codelist %>% 
  select(country_name = country.name.en, country = ecb)
```

As typical, the reproduction does not need to be identical, just close.

```{r echo = FALSE, fig.height = 10}
library(tidyverse)
library(lubridate)
library(ungeviz)
library(dviz.supp)
library(ggtext)
theme_set(
  theme_minimal(10) +
    theme(plot.title.position = "plot")
)

crime <- read_csv(here::here("data", "crime.csv")) %>% 
  janitor::clean_names()

transit_cost <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-01-05/transit_cost.csv')

country_codes <- countrycode::codelist %>% 
  select(country_name = country.name.en, country = ecb)

non_num <- c("AVG", "MEDIAN", "MIN", "MAX", "N", "QUARTILE 1", "QUARTILE 3", 
             "STD")

View(transit_cost)

transit <- transit_cost %>% 
  filter(!real_cost %in% non_num) %>% 
  mutate(real_cost = parse_number(real_cost)) %>% 
  left_join(country_codes)

transit_means <- transit %>% 
  group_by(country_name) %>% 
  summarize(
    n = n(),
    cost_mean = mean(real_cost, na.rm = TRUE),
    cost_se = sd(real_cost, na.rm = TRUE) / sqrt(n()),
    lower = cost_mean + qnorm(0.025) * cost_se,
    lower = ifelse(lower < 0, 0, lower),
    upper = cost_mean + qnorm(0.975) * cost_se
  ) %>% 
  filter(n >= 3) %>% 
  drop_na(country_name) %>% 
  mutate(country_name = fct_reorder(country_name, cost_mean))  

ggplot(transit_means, aes(cost_mean, country_name)) +
  geom_linerange(
    aes(xmin = lower, xmax = upper),
    color = "gray40"
  ) +
  geom_point(color = "#4375D3") +
  scale_x_continuous(
    name = "Real Cost (In millions of dollars)",
    labels = scales::dollar,
    expand = c(0, 0, .01, 0)
  ) +
  labs(
    title = "Cost to build transit systems vary across countries",
    caption = "Data provided through #tidytuesday by the Transit Costs Project",
    y = "Country"
  ) +
  theme(
    panel.grid.minor.x = element_blank(),
    panel.grid.major.y = element_blank()
  )
``` 

### Question 2

Visualize the same relation, but displaying the **uncertainty** using an alternative method of your choosing.

```{r viz2, eval = FALSE}
cols <- viridisLite::cividis(2)

ggplot(transit_means, aes(cost_mean, country_name)) +
  stat_confidence_density(aes(moe = cost_se), 
                          fill = cols[1], 
                          confidence = pnorm(.95)) +
  geom_segment(aes(y = as.numeric(country_name) - 0.4, 
                   yend = as.numeric(country_name) + 0.4, 
                   x = cost_mean, 
                   xend = cost_mean),
               color = cols[2],
               size = 0.9) +
  scale_x_continuous(name = "Real Cost (In millions of dollars)", 
                     labels = scales::dollar,
                     limits = c(0, 35000),
                     expand = c(0, 0, .01, 0)) +
  labs(title = "Cost to build transit systems vary across countries",
       caption = "Data provided through #tidytuesday by the Transit Costs Project",
       y = "Country") +
  theme(panel.grid.minor.x = element_blank(),
        panel.grid.major.y = element_blank())

```

### Question 3

Compute the mean `length` and `real_cost` by `city`. Reproduce the following plot.

* Hint: Look into `scale_size_binned()`

<br/>

```{r echo = FALSE}
pd2 <- transit %>% 
  group_by(country_name, city) %>% 
  summarize(
    n = n(),
    mean_length = mean(length, na.rm = TRUE),
    mean_real_cost = mean(real_cost, na.rm = TRUE)
  )
library(ggrepel)
ggplot(pd2, aes(mean_length, mean_real_cost)) +
  geom_point(aes(size = n), color = "gray80") +
  geom_point(
    aes(size = n),
    color = "#BF22CB",
    data = filter(pd2, country_name == "India")
  ) +
  scale_size_binned("Number of transit systems", breaks = c(5, 10, 20)) +
  scale_y_log10(name = "Average cost", labels = scales::dollar) +
  scale_x_log10("Average length") +
  geom_text_repel(
    aes(label = city),
    min.segment.length = 0,
    data = filter(pd2, country_name == "India")
  ) +
  labs(
    title = "Longer transit systems tend to cost more",
    subtitle = "<span style='color:#BF22CB'>India</span> has among the most transit systems in the world",
    caption = "Note the axes are on the log scale"
  ) +
  theme(
    legend.position = "bottom", 
    plot.subtitle = element_markdown()
  )
```

<br/>


### Question 4

Using basically the same data, reproduce the following plot. Note you'll need the `country_name` column in your dataset.

<br/>

```{r}
ggplot(pd2, aes(mean_length, mean_real_cost)) +
  geom_point(aes(size = n), color = "gray80") +
  geom_point(
    color = "#569FD1",
    data = filter(pd2, country_name == "United States")
  ) +
  ggforce::geom_mark_ellipse(
    aes(group = country_name, label = country_name),
    expand = unit(1, "mm"),
    color = "pink",
    label.colour = "#569FD1",
    con.colour = "pink",
    data = filter(pd2, country_name == "United States")
  ) +
  ggrepel::geom_label_repel(
    aes(label = city),
    label.padding = 0.1,
    color = "gray60",
    min.segment.length = 0,
    data = filter(pd2, country_name == "United States")
  ) +
  scale_size_binned(
    "Number of transit systems", 
    breaks = c(5, 10, 20)
  ) +
  scale_y_log10(
    name = "Average cost", 
    labels = scales::dollar
  ) +
  scale_x_log10("Average length") +
  labs(
    title = "Longer transit systems tend to cost more",
    caption = "Note the axes are on the log scale"
  ) +
  theme(
    legend.position = "bottom"
  )
```

<br/>
 
### Question 5

Use the crime dataset to run the following code and fit the corresponding 
model. Note, it may take a moment to run. 

```{r model, echo = TRUE}
model_data <- crime %>% 
  mutate(neighborhood_id = relevel(factor(neighborhood_id), ref = "barnum"))

m <- glm(is_crime ~ neighborhood_id, 
         data = model_data,
         family = "binomial")
```

This model uses neighborhood to predict whether a crime occurred or not. The 
reference group has been set to the "barnum" neighborhood, and the coefficents 
are all in comparison to this neighborhood. 

Extract the output using `broom::tidy`

```{r tidy, echo = TRUE}
tidied <- broom::tidy(m)
```

Divide the probability space, `[0, 1]`, into even bins of your choosing. For example, for 20 bins I could run the following

```{r ppoints, echo = TRUE}
ppoints(20)
```

The coefficients (`tidied$estimate`) for each district in the model represent the difference in crime rates between the corresponding neighborhood the Barnum neighborhood. These are reported on a log scale and can be exponentiated to provide the odds. For example the Athmar-Park neighborhood was estimated as `r round(exp(tidied$estimate[2]), 2)` times more likely to have a crime occur than the Barnum neighborhood. This is the point estimate, which is our "best guess" as to the true difference, and the likelihood of alternative differences are distributed around this point with a standard deviation equal to the standard error. We can simulate data from this distribution, if we choose, or instead just use the distribution to calculate different quantiles.  

The `qnorm` function transforms probabilities, such as those we generated with `ppoints`, into values according to some pre-defined normal distribution (by default it is a standard normal with a mean of zero and standard deviation of 1). For example `qnorm(.75, mean = 100, sd = 10)` provides the 75th percentile value from a distribution with a mean of 100 and a standard deviation of 10. We can therefore use `qnorm` in conjunction with `ppoints` to better understand the sampling distribution and, ultimately, communicate uncertainty. For example the following code generates the values corresponding to `ppoints(20)`, or 2.5th to 97.5th percentiles of the distributions in 5 percentile "jumps", for the difference in crime rates on the log scale for Barnum and Regis neighborhoods.

```{r qnorm, echo = TRUE}
regis <- tidied %>% 
  filter(term == "neighborhood_idregis")

qnorm(ppoints(20), 
      mean = regis$estimate,
      sd = regis$std.error)
```

The following plot displays a discretized version of the probability space for the differences in crime between the neighborhoods. Replicate this plot, but comparing the Barnum neighborhood to the Barnum-West neighborhood. Make sure to put the values in a data frame, and create a  new variable stating whether the difference is greater than zero (which you will use to fill by). Note that you do not need to replicate the colors in the subtitle to match the balls, as I have, but if you'd like to you should likely use the [ggtext](https://github.com/wilkelab/ggtext) package.

**Note:** Your probabilities will not directly correspond with the *p* values, which are essentially twice the probability you are displaying (because the test is two-tailed).

```{r dotplot, fig.height = 8}
regis <- tidied %>% 
  filter(term == "neighborhood_idregis")

diff <- data.frame(balls = qnorm(ppoints(20), 
                                 mean = regis$estimate,
                                 sd = regis$std.error)) %>% 
  mutate(higher_crime = ifelse(balls < 0, "Regis", "Barnum"))

ggplot(diff, aes(balls)) +
  geom_dotplot(aes(fill = higher_crime), binwidth = 0.045) +
  scale_fill_manual(values = c("#1EB48E", "#8A7D98")) +
  scale_y_continuous("", 
                     breaks = NULL, 
                     expand = c(0, 0)) +
  scale_x_continuous("Difference in log odds of a crime being committed",
                     breaks = seq(-0.1, 0.2, .05),
                     expand = c(0.015, 0.015)) +
  geom_vline(xintercept = 0.002, color = "#D04343", size = 2) +
  labs(title = "Probability of differential crime rates between neighborhoods", 
       subtitle = "<span style='color:#8A7D98'>**Regis** </span>compared to <span style='color:#1EB48E'>**Barnum**</span>",
       caption = "Each ball represents 5% probability") +
  guides(fill = "none") +
  theme(plot.subtitle = element_markdown())
```